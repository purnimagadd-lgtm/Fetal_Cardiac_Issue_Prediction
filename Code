import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.preprocessing import StandardScaler
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingRandomSearchCV
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import SGDClassifier, LogisticRegression
df = pd.read_csv('C:/Users/gvc85/Downloads/fetal_health.csv')
df.head()
X = df.drop('fetal_health', axis = 1)
y = df.fetal_health
rng = np.random.randint(2 ** 10)
X, y = make_classification(n_samples=2126, random_state=rng)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)
clf = ("AdaBoost",AdaBoostClassifier()),
("Decision Tree", DecisionTreeClassifier(max_depth=10)),
("Gaussian Process", GaussianProcessClassifier()),
("Linear SVM", SVC(kernel="linear", C=0.025,probability=True)),
("Naive Bayes",GaussianNB()),
("Nearest Neighbors",KNeighborsClassifier(3)),
("Neural Net",MLPClassifier(alpha=1)),
("QDA", QuadraticDiscriminantAnalysis()),
("Random Forest",RandomForestClassifier(n_jobs=2, random_state=1)),
("RBF SVM",SVC(gamma=2, C=1,probability=True)),
("SGDClassifier", SGDClassifier(max_iter=1000, tol=10e-3,penalty='elasticnet'))
param_dist = {}
from matplotlib import pyplot as plt
from sklearn.metrics import plot_confusion_matrix
clf_names = []
train_scores = []
test_scores = []
for n,clf in clf:
 clf_names.append(n)
 rsh = HalvingRandomSearchCV(clf,param_dist, refit=True)
 rsh.fit(X_train, y_train)
 print(n+" training done!")
 train_scores.append(rsh.score(X_train, y_train))
 disp = plot_confusion_matrix(rsh, X_train, y_train,
 display_labels=['ROCK','MINE'],
 cmap=plt.cm.Blues,
 normalize=None)
 disp.ax_.set_title('Confusion matrix')
 print('Train results: confusion matrix')
 print(disp.confusion_matrix)
 a=disp.confusion_matrix[0][0]
 b=disp.confusion_matrix[0][1]
 c=disp.confusion_matrix[1][0]
 d=disp.confusion_matrix[1][1]
 print('Pre train :',a/(a+b))
 print('Rec train :',a/(a+c))
 print('f1 train :', 2*(1/((1/(a/(a+b)))+(1/(a/(a+c))))))
 test_scores.append(rsh.score(X_test, y_test))
 disp = plot_confusion_matrix(rsh, X_test, y_test,display_labels=['ROCK','cmap=plt.cm.Blues, normalize=None) disp.ax_.set_title('Confusion matrix') print('Test results: confusion matrix') print(disp.confusion_matrix)
                  a1=disp.confusion_matrix[0][0]
                    b1=disp.confusion_matrix[0][1]
                      c1=disp.confusion_matrix[1][0]
                        d1=disp.confusion_matrix[1][1]]
 print('Pre_test :',a1/(a1+b1))
 print('Rec train :',a1/(a1+c1))
 print('f1 test :', 2*(1/((1/(a1/(a1+b1)))+(1/(a1/(a1+c1))))))
 print("---")
